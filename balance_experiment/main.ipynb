{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['__NV_PRIME_RENDER_OFFLOAD'] = '1'\n",
    "os.environ['__GLX_VENDOR_LIBRARY_NAME'] = 'nvidia'\n",
    "os.environ['MUJOCO_GL'] = 'egl'\n",
    "\n",
    "# Tell XLA to use Triton GEMM, this improves steps/sec by ~30% on some GPUs\n",
    "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
    "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
    "os.environ['XLA_FLAGS'] = xla_flags\n",
    "\n",
    "from functools import partial\n",
    "from brax.training.agents.ppo import networks as ppo_networks\n",
    "from brax.training.agents.ppo import train as ppo\n",
    "import wandb\n",
    "\n",
    "\n",
    "import jax\n",
    "import mediapy as media\n",
    "from randomize import domain_randomize\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import balance\n",
    "env = partial(balance.G1Env)()\n",
    "env_cfg = balance.default_config()\n",
    "\n",
    "# jit_reset = jax.jit(env.reset)\n",
    "# jit_step = jax.jit(env.step)\n",
    "# state = jit_reset(jax.random.PRNGKey(0))\n",
    "# rollout = [state]\n",
    "\n",
    "# f = 0.5\n",
    "\n",
    "# for i in tqdm(range(200)):\n",
    "#   action = []\n",
    "#   for j in range(env.action_size):\n",
    "\n",
    "#     if env.mj_model.actuator(j).name == \"right_knee_joint\" or env.mj_model.actuator(j).name == \"left_shoulder_roll_joint\":\n",
    "#       value = jp.sin(\n",
    "#             state.data.time * 2 * jp.pi * f \n",
    "#         ) * 1.\n",
    "#     else:\n",
    "#       value = 0.\n",
    "      \n",
    "#     action.append( value)\n",
    "#   action = jp.array(action)\n",
    "#   state = jit_step(state, action)\n",
    "#   rollout.append(state)\n",
    "# frames = env.render(rollout, camera=\"track\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "env_name = \"g1_balance\"\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%Y%m%d-%H%M%S\")\n",
    "exp_name = f\"{env_name}-{timestamp}\"\n",
    "import os\n",
    "\n",
    "ckpt_path = os.path.abspath(os.path.join(\".\", \"checkpoints\", exp_name))\n",
    "os.makedirs(ckpt_path, exist_ok=True)\n",
    "print(f\"Checkpoint path: {ckpt_path}\")# media.show_video(frames, fps=1.0 / env.dt)\n",
    "\n",
    "\n",
    "wandb.init(project=\"mjxrl\", config=env_cfg)\n",
    "wandb.config.update({\n",
    "    \"env_name\": env_name,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_collections import config_dict\n",
    "# ppo_params= config_dict.create(\n",
    "#     num_timesteps=1_000_000,\n",
    "#     num_evals=10,\n",
    "#     reward_scaling=10.0,\n",
    "#     episode_length=env_cfg.episode_length,\n",
    "#     normalize_observations=True,\n",
    "#     action_repeat=1,\n",
    "#     unroll_length=30,\n",
    "#     num_minibatches=32,\n",
    "#     num_updates_per_batch=16,\n",
    "#     discounting=0.995,\n",
    "#     learning_rate=1e-3,\n",
    "#     entropy_cost=1e-2,\n",
    "#     num_envs=2048,\n",
    "#     batch_size=1024,\n",
    "# )\n",
    "\n",
    "from ml_collections import config_dict\n",
    "ppo_params= config_dict.create(\n",
    "    num_timesteps=60_000_000,\n",
    "    reward_scaling=10.0,\n",
    "    episode_length=env_cfg.episode_length,\n",
    "    normalize_observations=True,\n",
    "    action_repeat=1,\n",
    "    unroll_length=30,\n",
    "    num_minibatches=32,\n",
    "    num_updates_per_batch=16,\n",
    "    discounting=0.995,\n",
    "    learning_rate=1e-3,\n",
    "    entropy_cost=1e-2,\n",
    "    num_envs=2048,\n",
    "    batch_size=1024,\n",
    "    num_evals=0,\n",
    "    log_training_metrics=True\n",
    ")\n",
    "x_data, y_data, y_dataerr = [], [], []\n",
    "times = [datetime.now()]\n",
    "\n",
    "\n",
    "def progress_cli(num_steps, metrics):\n",
    "  \"\"\"Prints progress metrics to the console, including all available metrics.\"\"\"\n",
    "\n",
    "  wandb.log(metrics, step=num_steps)\n",
    "\n",
    "  # Print the current step number\n",
    "  print(f\"Step: {num_steps}\")\n",
    "\n",
    "  # Print the entire metrics dictionary for debugging\n",
    "  print(\"Metrics:\", metrics)\n",
    "\n",
    "  # You can add a separator for clarity if you run this multiple times\n",
    "  print(\"-\" * 20)\n",
    "\n",
    "ppo_training_params = dict(ppo_params)\n",
    "network_factory = ppo_networks.make_ppo_networks\n",
    "if \"network_factory\" in ppo_params:\n",
    "  del ppo_training_params[\"network_factory\"]\n",
    "  network_factory = partial(\n",
    "      ppo_networks.make_ppo_networks,\n",
    "      **ppo_params.network_factory\n",
    "  )\n",
    "\n",
    "train_fn = partial(\n",
    "    ppo.train, **dict(ppo_training_params),\n",
    "    network_factory=network_factory,\n",
    "    progress_fn=progress_cli\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mujoco_playground import wrapper\n",
    "\n",
    "make_inference_fn, params, metrics = train_fn(\n",
    "    environment=env,\n",
    "    wrap_env_fn=wrapper.wrap_for_brax_training,\n",
    "    # randomization_fn=domain_randomize,\n",
    ")\n",
    "# print(f\"time to jit: {times[1] - times[0]}\")\n",
    "# print(f\"time to train: {times[-1] - times[1]}\")\n",
    "# # ~6m11s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_reset = jax.jit(env.reset)\n",
    "jit_step = jax.jit(env.step)\n",
    "jit_inference_fn = jax.jit(make_inference_fn(params, deterministic=True))\n",
    "rng = jax.random.PRNGKey(42)\n",
    "rollout = []\n",
    "n_episodes = 1\n",
    "\n",
    "for _ in range(n_episodes):\n",
    "  state = jit_reset(rng)\n",
    "  rollout.append(state)\n",
    "  for i in range(env_cfg.episode_length):\n",
    "    act_rng, rng = jax.random.split(rng)\n",
    "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
    "    state = jit_step(state, ctrl)\n",
    "    rollout.append(state)\n",
    "\n",
    "render_every = 1\n",
    "frames = env.render(rollout[::render_every])\n",
    "rewards = [s.reward for s in rollout]\n",
    "media.show_video(frames, fps=1.0 / env.dt / render_every)\n",
    "# ~11s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
