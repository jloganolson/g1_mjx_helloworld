{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['__NV_PRIME_RENDER_OFFLOAD'] = '1'\n",
    "os.environ['__GLX_VENDOR_LIBRARY_NAME'] = 'nvidia'\n",
    "os.environ['MUJOCO_GL'] = 'egl'\n",
    "\n",
    "# Tell XLA to use Triton GEMM, this improves steps/sec by ~30% on some GPUs\n",
    "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
    "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
    "os.environ['XLA_FLAGS'] = xla_flags\n",
    "\n",
    "import mujoco\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from brax.training.agents.ppo import networks as ppo_networks\n",
    "from brax.training.agents.ppo import train as ppo\n",
    "\n",
    "from IPython.display import  clear_output\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapy as media\n",
    "from tqdm import tqdm\n",
    "from randomize import domain_randomize\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import balance\n",
    "env = partial(balance.G1Env)()\n",
    "env_cfg = balance.default_config()\n",
    "\n",
    "# jit_reset = jax.jit(env.reset)\n",
    "# jit_step = jax.jit(env.step)\n",
    "# state = jit_reset(jax.random.PRNGKey(0))\n",
    "# rollout = [state]\n",
    "\n",
    "# f = 0.5\n",
    "\n",
    "# for i in tqdm(range(200)):\n",
    "#   action = []\n",
    "#   for j in range(env.action_size):\n",
    "\n",
    "#     if env.mj_model.actuator(j).name == \"right_knee_joint\" or env.mj_model.actuator(j).name == \"left_shoulder_roll_joint\":\n",
    "#       value = jp.sin(\n",
    "#             state.data.time * 2 * jp.pi * f \n",
    "#         ) * 1.\n",
    "#     else:\n",
    "#       value = 0.\n",
    "      \n",
    "#     action.append( value)\n",
    "#   action = jp.array(action)\n",
    "#   state = jit_step(state, action)\n",
    "#   rollout.append(state)\n",
    "# frames = env.render(rollout, camera=\"track\")\n",
    "# media.show_video(frames, fps=1.0 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_collections import config_dict\n",
    "# ppo_params= config_dict.create(\n",
    "#     num_timesteps=1_000_000,\n",
    "#     num_evals=10,\n",
    "#     reward_scaling=10.0,\n",
    "#     episode_length=env_cfg.episode_length,\n",
    "#     normalize_observations=True,\n",
    "#     action_repeat=1,\n",
    "#     unroll_length=30,\n",
    "#     num_minibatches=32,\n",
    "#     num_updates_per_batch=16,\n",
    "#     discounting=0.995,\n",
    "#     learning_rate=1e-3,\n",
    "#     entropy_cost=1e-2,\n",
    "#     num_envs=2048,\n",
    "#     batch_size=1024,\n",
    "# )\n",
    "\n",
    "from ml_collections import config_dict\n",
    "ppo_params= config_dict.create(\n",
    "    num_timesteps=60_000_000,\n",
    "    reward_scaling=10.0,\n",
    "    episode_length=env_cfg.episode_length,\n",
    "    normalize_observations=True,\n",
    "    action_repeat=1,\n",
    "    unroll_length=30,\n",
    "    num_minibatches=32,\n",
    "    num_updates_per_batch=16,\n",
    "    discounting=0.995,\n",
    "    learning_rate=1e-3,\n",
    "    entropy_cost=1e-2,\n",
    "    num_envs=2048,\n",
    "    batch_size=1024,\n",
    "    num_evals=0,\n",
    "    log_training_metrics=True\n",
    ")\n",
    "x_data, y_data, y_dataerr = [], [], []\n",
    "times = [datetime.now()]\n",
    "\n",
    "\n",
    "def progress_cli(num_steps, metrics):\n",
    "  \"\"\"Prints progress metrics to the console, including all available metrics.\"\"\"\n",
    "\n",
    "  # Print the current step number\n",
    "  print(f\"Step: {num_steps}\")\n",
    "\n",
    "  # Print the entire metrics dictionary for debugging\n",
    "  print(\"Metrics:\", metrics)\n",
    "\n",
    "  # You can add a separator for clarity if you run this multiple times\n",
    "  print(\"-\" * 20)\n",
    "\n",
    "ppo_training_params = dict(ppo_params)\n",
    "network_factory = ppo_networks.make_ppo_networks\n",
    "if \"network_factory\" in ppo_params:\n",
    "  del ppo_training_params[\"network_factory\"]\n",
    "  network_factory = partial(\n",
    "      ppo_networks.make_ppo_networks,\n",
    "      **ppo_params.network_factory\n",
    "  )\n",
    "\n",
    "train_fn = partial(\n",
    "    ppo.train, **dict(ppo_training_params),\n",
    "    network_factory=network_factory,\n",
    "    progress_fn=progress_cli\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/logan/miniconda3/envs/g1/lib/python3.10/site-packages/jax/_src/interpreters/xla.py:132: RuntimeWarning: overflow encountered in cast\n",
      "  return np.asarray(x, dtypes.canonicalize_dtype(x.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 245760\n",
      "Metrics: {'episode/length': np.float64(48.56), 'episode/reward/dof_pos_limits': np.float64(-1.1564310322701932), 'episode/reward/height': np.float64(3.138432297061663), 'episode/reward/orientation': np.float64(14.137529747486115), 'episode/reward/pose': np.float64(-5.937100163698196), 'episode/sum_reward': np.float64(0.20364861333742737)}\n",
      "--------------------\n",
      "Step: 491520\n",
      "Metrics: {'episode/length': np.float64(42.27), 'episode/reward/dof_pos_limits': np.float64(-0.6049358803220093), 'episode/reward/height': np.float64(1.5855725535817329), 'episode/reward/orientation': np.float64(10.892314279079438), 'episode/reward/pose': np.float64(-2.643221758008003), 'episode/sum_reward': np.float64(0.18459457702934742)}\n",
      "--------------------\n",
      "Step: 737280\n",
      "Metrics: {'episode/length': np.float64(43.74), 'episode/reward/dof_pos_limits': np.float64(-0.6541939178109168), 'episode/reward/height': np.float64(1.80118247309234), 'episode/reward/orientation': np.float64(11.423776710033417), 'episode/reward/pose': np.float64(-2.735170292854309), 'episode/sum_reward': np.float64(0.19671189460903407)}\n",
      "--------------------\n",
      "Step: 983040\n",
      "Metrics: {'episode/length': np.float64(45.73), 'episode/reward/dof_pos_limits': np.float64(-0.7128602477908135), 'episode/reward/height': np.float64(2.098788097208599), 'episode/reward/orientation': np.float64(12.090858886241913), 'episode/reward/pose': np.float64(-2.967439900636673), 'episode/sum_reward': np.float64(0.21018692879006268)}\n",
      "--------------------\n",
      "Step: 1228800\n",
      "Metrics: {'episode/length': np.float64(47.08), 'episode/reward/dof_pos_limits': np.float64(-0.7203556761145592), 'episode/reward/height': np.float64(2.3473865645990006), 'episode/reward/orientation': np.float64(12.527474377155304), 'episode/reward/pose': np.float64(-3.092385119199753), 'episode/sum_reward': np.float64(0.221242401227355)}\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from mujoco_playground import wrapper\n",
    "\n",
    "make_inference_fn, params, metrics = train_fn(\n",
    "    environment=env,\n",
    "    wrap_env_fn=wrapper.wrap_for_brax_training,\n",
    "    randomization_fn=domain_randomize,\n",
    ")\n",
    "# print(f\"time to jit: {times[1] - times[0]}\")\n",
    "# print(f\"time to train: {times[-1] - times[1]}\")\n",
    "# # ~6m11s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 263/1001 [00:19<00:54, 13.45it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     rollout\u001b[38;5;241m.\u001b[39mappend(state)\n\u001b[1;32m     17\u001b[0m render_every \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 18\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[43mrender_every\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m rewards \u001b[38;5;241m=\u001b[39m [s\u001b[38;5;241m.\u001b[39mreward \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m rollout]\n\u001b[1;32m     20\u001b[0m media\u001b[38;5;241m.\u001b[39mshow_video(frames, fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m env\u001b[38;5;241m.\u001b[39mdt \u001b[38;5;241m/\u001b[39m render_every)\n",
      "File \u001b[0;32m~/Projects/mujoco_playground/mujoco_playground/_src/mjx_env.py:290\u001b[0m, in \u001b[0;36mMjxEnv.render\u001b[0;34m(self, trajectory, height, width, camera, scene_option, modify_scene_fns)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    281\u001b[0m     trajectory: List[State],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    288\u001b[0m     ] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    289\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m--> 290\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrender_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmj_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrajectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m      \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m      \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcamera\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m      \u001b[49m\u001b[43mscene_option\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscene_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodify_scene_fns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodify_scene_fns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/mujoco_playground/mujoco_playground/_src/mjx_env.py:343\u001b[0m, in \u001b[0;36mrender_array\u001b[0;34m(mj_model, trajectory, height, width, camera, scene_option, modify_scene_fns, hfield_data)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m       modify_scene_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m     out\u001b[38;5;241m.\u001b[39mappend(\u001b[43mget_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodify_scene_fn\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    345\u001b[0m   out \u001b[38;5;241m=\u001b[39m get_image(trajectory)\n",
      "File \u001b[0;32m~/Projects/mujoco_playground/mujoco_playground/_src/mjx_env.py:334\u001b[0m, in \u001b[0;36mrender_array.<locals>.get_image\u001b[0;34m(state, modify_scn_fn)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modify_scn_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m   modify_scn_fn(renderer\u001b[38;5;241m.\u001b[39mscene)\n\u001b[0;32m--> 334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/g1/lib/python3.10/site-packages/mujoco/renderer.py:243\u001b[0m, in \u001b[0;36mRenderer.render\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    241\u001b[0m   np\u001b[38;5;241m.\u001b[39mcopyto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scene\u001b[38;5;241m.\u001b[39mflags, original_flags)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 243\u001b[0m   \u001b[43m_render\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmjr_readPixels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mjr_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m out[:] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mflipud(out)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "jit_reset = jax.jit(env.reset)\n",
    "jit_step = jax.jit(env.step)\n",
    "jit_inference_fn = jax.jit(make_inference_fn(params, deterministic=True))\n",
    "rng = jax.random.PRNGKey(42)\n",
    "rollout = []\n",
    "n_episodes = 1\n",
    "\n",
    "for _ in range(n_episodes):\n",
    "  state = jit_reset(rng)\n",
    "  rollout.append(state)\n",
    "  for i in range(env_cfg.episode_length):\n",
    "    act_rng, rng = jax.random.split(rng)\n",
    "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
    "    state = jit_step(state, ctrl)\n",
    "    rollout.append(state)\n",
    "\n",
    "render_every = 1\n",
    "frames = env.render(rollout[::render_every])\n",
    "rewards = [s.reward for s in rollout]\n",
    "media.show_video(frames, fps=1.0 / env.dt / render_every)\n",
    "# ~11s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
